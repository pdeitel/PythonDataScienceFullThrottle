{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e844d02f-5866-4d03-8021-71643b07bba8",
   "metadata": {},
   "source": [
    "&copy; 2024 by Deitel & Associates, Inc. All Rights Reserved. https://deitel.com\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f59efb-5fe1-44a6-ba3a-398ee1168782",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "    h1 {color:#BB0000}\n",
    "    h2 {color:purple}\n",
    "    h3 {color:#0099ff}\n",
    "    hr {    \n",
    "        border: 0;\n",
    "        height: 3px;\n",
    "        background: #333;\n",
    "        background-image: linear-gradient(to right, #ccc, black, #ccc);\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd7343-5179-4ac1-b5d9-7557fde17f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable high-res images in notebook \n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355603c3-953e-435c-8a67-0c6540362a87",
   "metadata": {},
   "source": [
    "# What is Generative AI?\n",
    "* AI that creates content\n",
    "    * Text, images, audio, video, music, poetry, code, ...\n",
    "    * Makes content creation accessible to everyone\n",
    "* Can be tailored to specific requirements\n",
    "* References\n",
    "    * https://en.wikipedia.org/wiki/Generative_artificial_intelligence\n",
    "    * https://www.techtarget.com/searchenterpriseai/definition/generative-AI\n",
    "    * https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-generative-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf9f690-76c3-4339-91e9-ae2771e3365a",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320b5a3-76a4-4925-98d5-04a2709268c3",
   "metadata": {},
   "source": [
    "# What is a Large Language Model (LLM)?\n",
    "* AI that understands/generates natural language \n",
    "* \"Large\" — Neural nets with **billions**, and now **trillions**, of parameters\n",
    "    * As neural nets learn, they tune parameters in an effort to produce better results\n",
    "    * Parameters helps models understand/generate language patterns \n",
    "* Trained on massive amounts of text\n",
    "    * books, articles, the Internet, code, ...\n",
    "* Great at natural language tasks\n",
    "    * Translation, summarization, answering questions, sentiment analysis, creative writing, ...\n",
    "    * Also generating code, explaining code, finding errors in code, ...\n",
    "* Can generate text indistinguishable from human writing\n",
    "* Some continue to learn and adapt, improving effectiveness over time\n",
    "* Many LLMs use **generative pretrained transformers (GPTs)**\n",
    "* References\n",
    "    * https://en.wikipedia.org/wiki/Large_language_model\n",
    "    * https://www.techtarget.com/whatis/definition/large-language-model-LLM\n",
    "    * https://machinelearningmastery.com/what-are-large-language-models/\n",
    "* There are other techniques, like **Bidirectional Encoder Representations from Transformers (BERT)**\n",
    "    * https://en.wikipedia.org/wiki/BERT_(language_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7608f0a8-b8f0-4569-a672-5f769603f380",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffaa890-9d62-40c1-b905-ffcbcea9d394",
   "metadata": {},
   "source": [
    "# What is a Transformer? \n",
    "* Neural network that processes sequential data, like text\n",
    "* Can understand/recognize relationships between distant words in a sentence \n",
    "* Also recognizes the relative importance of words \n",
    "* References for Transformers\n",
    "    * https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)  \n",
    "    * https://blogs.nvidia.com/blog/what-is-a-transformer-model/\n",
    "    * https://towardsdatascience.com/transformers-141e32e69591"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf21e9a-f943-4d46-aadc-4675575af1ee",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed601e9-57c7-40fe-9279-e23e1978101e",
   "metadata": {},
   "source": [
    "# What is a Self-Attention? \n",
    "* Key aspect of transformers\n",
    "* When you try to understand a word in a sentence, words around it (its context) can help you understand the meaning\n",
    "    * \"good\" is positive, but preceding it with \"not\" makes the context negative\n",
    "* Transformers use self-attention to understand each word by looking at other words around it\n",
    "    * Words are not equally important \n",
    "    * Self-attention weighs which words to pay attention to when trying to understand each word\n",
    "* Unlike humans, transformers can consider massive numbers of words in parallel to understand how words are connected\n",
    "* References for Self-Attention \n",
    "    * https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a\n",
    "    * https://en.wikipedia.org/wiki/Attention_(machine_learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c2f5a-fdde-4bf0-a71d-ec50cda64706",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c34f758-d14a-4bac-b122-8dcf7b60095e",
   "metadata": {},
   "source": [
    "# Tokens, Context and Context Windows \n",
    "* Token \n",
    "    * Unit of processing in language models\n",
    "    * Words, parts of words, punctuation\n",
    "    * Tokenization converts tokens to numerical values models can process\n",
    "    * Models typically have token limits\n",
    "* Context\n",
    "    * Sequence of tokens that comes before (and sometimes after) a word/phrase\n",
    "    * Understanding context helps models generate more accurate responses\n",
    "* Context window\n",
    "    * Maximum range of tokens (both input and output) model can consider at once\n",
    "    * Larger == more context to the conversation == more relevant/coherent responses\n",
    "    * Google Gemini 1 million tokens\n",
    "    > https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#context-window\n",
    "    * Claude.ai Pro 200K tokens\n",
    "    > https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#context-window\n",
    "    * GPT-4 Turbo (OpenAI) 128K tokens\n",
    "    > https://platform.openai.com/docs/models/overview\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da79c7e0-8cba-4d08-90b9-79a06799f9c5",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a54814-9b25-4b33-a734-d05c7a5c592f",
   "metadata": {},
   "source": [
    "# Prompts and Prompt Engineering\n",
    "* Poor prompts, lead to poor results — \"garbage in, garbage out\"\n",
    "* Prompt engineering is the process of desining prompts to obtain the best responses\n",
    "* OpenAI provides various strategies\n",
    "    * https://platform.openai.com/docs/guides/prompt-engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9248ffd9-ef59-4b70-9b5e-0fe1e5802dca",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd171ebf-4ed9-44c9-8690-10c2d952ed4e",
   "metadata": {},
   "source": [
    "# Issues with Generative AI\n",
    "* Ethics — e.g., misinformation, realistic images/videos\n",
    "* Biases\n",
    "* **Hallucinations** — They sometime make up facts\n",
    "* Copyrights\n",
    "    * NYT Sues OpenAI: https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html\n",
    "* Picks up human traits? \n",
    "    * ChatGPT gets lazy (“winter break hypothesis”): https://arstechnica.com/information-technology/2023/12/is-chatgpt-becoming-lazier-because-its-december-people-run-tests-to-find-out/)\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd30659f-8abe-4677-802c-50cbde5b20fb",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a671a-2af3-4e86-9b99-2402fe59caf1",
   "metadata": {},
   "source": [
    "# OpenAI \n",
    "* https://openai.com/\n",
    "* One of many generative AI providers \n",
    "* Creator of ChatGPT, Dall-E\n",
    "* APIs for\n",
    "    * Audio — speech-to-text, text-to-speech, translation\n",
    "    * Chat (ChatGPT) \n",
    "    * Fine - tuning—tailoring to your own data\n",
    "    * Images (Dall-E)\n",
    "    * Models — explains all the available models\n",
    "    * Moderations — checks content policy violations\n",
    "    * Assistants — create assitants that can perform step-by-step tasks\n",
    "    * more...\n",
    "* OpenAI Cookbook — loaded with examples: https://cookbook.openai.com/\n",
    "* OpenAI Docs — tutorials, guides, ...: https://platform.openai.com/docs/overview\n",
    "* OpenAI API Reference: https://platform.openai.com/docs/api-reference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7919c11f-fece-405b-a15f-106214ea45ae",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62289243-1d8c-44e6-9e94-717096f8a2a8",
   "metadata": {},
   "source": [
    "# Installing the OpenAI Python Module\n",
    "* `pip install --upgrade openai`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849fd80-5574-4422-836b-c28dca800e87",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94978520-eacc-417c-926f-35d60fa34ff3",
   "metadata": {},
   "source": [
    "# Get an OpenAI Developer Account\n",
    "* Signup: https://platform.openai.com/signup\n",
    "* Pricing — small free credit depending on location \n",
    "> https://openai.com/pricing\n",
    "* Rate Limits \n",
    "> https://platform.openai.com/docs/guides/rate-limits/rate-limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e2d036-46ce-4a05-b204-d448948c3ce2",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e066db-d053-467c-9040-fe51f0742792",
   "metadata": {},
   "source": [
    "## OpenAI Developer API Key\n",
    "* While signed into your account\n",
    "    * Go to https://platform.openai.com/docs/overview\n",
    "    * Hover over the icons at the left of the page and click the **API keys** icon (looks like a padlock)\n",
    "    * Click **Create new secret key**\n",
    "    * Optionally name your key\n",
    "    * Click **Create secret key**\n",
    "    * Copy the lengthy alphanumeric key\n",
    "    * Follow instructions for your platform at https://platform.openai.com/docs/quickstart to store the API key in an environment variable\n",
    "    * **Restart your command line before launching iPython or Jupyter Lab**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7591dfd7-8ed6-4525-8506-932fabbe0ec7",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05832ed-e175-4e97-88b6-3288278949b1",
   "metadata": {},
   "source": [
    "# Some of OpenAIs Models with APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9a4a52-ea55-41c1-9cf7-2c8fab299d5b",
   "metadata": {},
   "source": [
    "| MODEL | DESCRIPTION |\n",
    "|-------|-------------|\n",
    "| GPT-4o | Current high-intelligence model. Can handle complex, multi-step tasks. |\n",
    "| GPT-4o mini | Smaller, more affordable model than the flagship GPT-4o model. Meant for fast, lightweight tasks. |\n",
    "| GPT-4 & GPT-4 Turbo | Latest models. Understand/generate natural language or code. |\n",
    "| GPT-3.5 | Previous models. Understand/generate natural language or code. |\n",
    "| DALL·E | Generates/edits images in response to natural language prompts. |\n",
    "| TTS | Converts text to speech. |\n",
    "| Whisper | Transcribes and translates audio. |\n",
    "| Embeddings | Converts text into numerical form. |\n",
    "| Moderation | Detects sensitive/unsafe text. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1954d544-b670-4fe1-b24e-696385557a3a",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41957275-3236-44d5-83a8-8ffc734c92fd",
   "metadata": {},
   "source": [
    "# Speech-to-Text, Text-to-Speech, Language Translation\n",
    "* Based on OpenAI's tutorial: Creating an automated meeting minutes generator with Whisper and GPT-4\n",
    "> https://platform.openai.com/docs/tutorials/meeting-minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb172cc-2ce0-459d-ac84-75ba3e6a0da7",
   "metadata": {},
   "source": [
    "## Importing the Modules for This Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3daf0b-bef4-4cf8-8597-64ddebc8e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI \n",
    "from docx import Document # for creating a Microsoft Word docx file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649878db-cde6-4dc6-b826-1239917d4015",
   "metadata": {},
   "source": [
    "## Creating the `OpenAI` Client Object\n",
    "* Provides access to the OpenAI APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ccd33e4-de7a-48cd-bc5a-13a6a5fb4ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de56d08-e6de-434b-a742-85c6053f9225",
   "metadata": {},
   "source": [
    "* Assumes your API key is in the environment variable `OPENAI_API_KEY`\n",
    "* If you used a different environment variable name, replace with preceding statement with\n",
    "> `client = OpenAI(api_key=os.environ.get(\"CUSTOM_ENV_NAME\"))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1a5798-c37f-48a7-a776-fb271916622b",
   "metadata": {},
   "source": [
    "## `speech_to_text` Function\n",
    "* Opens file at `audio_path` for reading in binary mode (`'rb'`)\n",
    "* Calls OpenAI `client` object's `audio.transcriptions.create` method \n",
    "    * passes `audio_file` to OpenAI's `whisper-1` model to create transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c95d9-7c2c-4ff7-bf8c-ed72dc333681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(audio_path):\n",
    "    with open(audio_path, 'rb') as audio_file:\n",
    "        transcript = client.audio.transcriptions.create(\n",
    "            model='whisper-1', file=audio_file)\n",
    "    return transcript.text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b43f11-8bca-4a4c-9836-aff692856669",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = speech_to_text('deep_learning_intro.m4a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d664117-656f-4fbf-b8fd-082078865a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f6c0a-46ac-4f15-beaf-1328e9692cdd",
   "metadata": {},
   "source": [
    "## `create_abstract` Function\n",
    "* `chat.completions.create` method responds to prompts, similar to interacting directly with ChatGPT through its web interface\n",
    "* `model` specifies OpenAI model that will formulate a response\n",
    "* Each item in `messages` list is a dictionary containing two keys\n",
    "    * `role`: `system`, `user` or `assistant`\n",
    "    * `content`: Prompt passed to the OpenAI model\n",
    "* Use `role`: `system` when prompting the model with details to help it perform a task\n",
    "* Use `role`: `user` when prompting for the task to perform\n",
    "* For more details about the message formats: https://cookbook.openai.com/examples/how_to_format_inputs_to_chatgpt_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a61d713-5ea8-4f9c-83df-e0493a648e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_abstract(transcript):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-2024-08-06',\n",
    "        messages=[\n",
    "            {'role': 'system',\n",
    "             'content': \"\"\"Given the following transcript of a \n",
    "                 technical presentation, create a summary abstract \n",
    "                 that is concise, clear, and written in a direct \n",
    "                 style suitable for a 10th-grade reading level. \n",
    "                 Focus on the key points of the presentation without \n",
    "                 referring to the speaker. Avoid using prepositional \n",
    "                 phrases and unnecessary words. Aim for straightforward \n",
    "                 sentence structures. Capture the presentation's \n",
    "                 essence, enabling a person to understand the presentation \n",
    "                 without having to read the full transcript. Format the \n",
    "                 abstract in a single, well-structured paragraph.\"\"\"},\n",
    "            {'role': 'user',\n",
    "             'content': transcript}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "    # Old way to get content--OpenAI tutorial is not yet up to date:\n",
    "    # return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a01dadc-f63d-4986-8782-3cf5775597db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary = create_abstract(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc6f63-9ea2-42d1-9683-9b9c05a3fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07214c5a-b2f0-4954-b45e-77f601a31512",
   "metadata": {},
   "source": [
    "## `get_key_points` Function\n",
    "* Prompt explains how GPT-4 should extract transcript's key points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45851334-0c26-4c01-856f-43ec16199031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_points(transcript):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "            {'role': 'system',\n",
    "             'content' : \"\"\"Given the following transcript of a \n",
    "                 technical presentation, identify and list the \n",
    "                 presentation's key points. Keep your writing \n",
    "                 concise, direct, and suitable for a 10th grade \n",
    "                 reading level. Avoid unnecessary words and excessive \n",
    "                 use of prepositional phrases. Aim for clear, \n",
    "                 straightforward sentence structures. Present this \n",
    "                 information as a numbered list, each point summarizing \n",
    "                 a separate key aspect of the presentation.\"\"\"},\n",
    "            {'role': 'user',\n",
    "             'content': transcript}\n",
    "        ]\n",
    "    )\n",
    "    #return response['choices'][0]['message']['content']\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50e1a80-9d54-49b4-b80e-7fa8618e3ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_points = get_key_points(transcript)\n",
    "print(key_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f95a2-ba67-4fef-95ff-c50d7f275d02",
   "metadata": {},
   "source": [
    "## `analyze_sentiment` Function\n",
    "* Prompt explains how GPT-4 should analyze transcript's sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc701a2e-16b8-46c0-a752-ccb2e5ffea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(transcript):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-2024-08-06',\n",
    "        messages=[\n",
    "            {'role': 'system',\n",
    "             'content': \"\"\"You are an expert in sentiment analysis. \n",
    "                 Analyze the following presentation transcript, then \n",
    "                 explain whether the sentiment is positive, negative, \n",
    "                 or neutral. Explain your analysis.\"\"\"},\n",
    "            {'role': 'user',\n",
    "             'content': transcript}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d0474-0e14-4837-868d-b67a5824431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = analyze_sentiment(transcript)\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec22d94-f427-4238-b52c-44af2c58f46b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## `save_as_docx` Function\n",
    "* Saves a dictionary of key-value pairs in `docx` format\n",
    "    * Used by Microsoft Word \n",
    "    * Supported by other word processors like Google Docs\n",
    "* Document headings are keys in `data_dict`\n",
    "    * Output as level 1 heading\n",
    "* Document contents are output as paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc60fa9-1b90-40a5-8c20-7d238552e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_docx(data_dict, filename):\n",
    "    document = Document() \n",
    "    \n",
    "    for heading, content in data_dict.items():\n",
    "        document.add_heading(heading, level=1)\n",
    "        document.add_paragraph(content)\n",
    "        \n",
    "    document.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d373ba97-071b-4a87-b431-debd6c69e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'Presentation Overview': summary,\n",
    "    'Key Points': key_points,\n",
    "    'Sentiment Analysis': sentiment\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87267f2-3e7d-46d2-adc6-0633427fd136",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_docx(data_dict, 'presentation_summary.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b8874-07dc-4041-bcf5-d8bcc5054a19",
   "metadata": {},
   "source": [
    "## `text_to_speech` Function\n",
    "* Synthesizes speech using OpenAI Audio API\n",
    "* Model `'tts-1-hd'` supports 6 voices and 57 languages\n",
    "    * Voices optimized for English, but can speak other languages\n",
    "* Supports streaming audio with chunk transfer encoding\n",
    "* MP3 is default format\n",
    "    * Also supports Opus (Internet streaming), AAC (compressed), FLAC (lossless)\n",
    "* Can't control emotion (yet)\n",
    "> \"There is no direct mechanism to control the emotional output of the audio generated. Certain factors may influence the output audio like capitalization or grammar but our internal tests with these have yielded mixed results.\" (https://platform.openai.com/docs/guides/text-to-speech/faq)\n",
    "* For more info, see **Text to speech** guide:\n",
    "> https://platform.openai.com/docs/guides/text-to-speech/voice-options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2542b2-1c6c-47e0-860f-1554b95de497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech(text, filename):\n",
    "    response = client.audio.speech.create(\n",
    "        model='tts-1-hd',\n",
    "        voice='onyx',\n",
    "        input=text\n",
    "    )\n",
    "\n",
    "    response.stream_to_file(f'{filename}.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c765e1b-8f72-402c-966e-ce41cbf468a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_speech(summary, 'english_summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4378990f-0b3b-451a-9c0d-57d7b3080a85",
   "metadata": {},
   "source": [
    "* `IPython` module provides various utilities, including an audio player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552fdd53-540c-47bc-ae1f-6f8d1f9634a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio('english_summary.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41613ba-5716-4a50-940d-0d70cbb68599",
   "metadata": {},
   "source": [
    "# `translate` Function\n",
    "* Text translation via chat completion\n",
    "* `system` role's `content` prompt tells chat completion how to operate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7b2f1d-84f4-4c54-bf74-bab4ee5d94a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text, language):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-2024-08-06',\n",
    "        messages=[\n",
    "            {'role': 'system',\n",
    "             'content': f\"\"\"You are an expert in natural language translation.\n",
    "                 Translate the following text into {language}.\"\"\"},\n",
    "            {'role': 'user',\n",
    "             'content': text}\n",
    "        ]\n",
    "    )\n",
    "    #return response['choices'][0]['message']['content']\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da751f3b-5411-45ac-b1f5-511a17733212",
   "metadata": {},
   "source": [
    "## Text to Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199c1e7-5446-4a78-a8e7-bf66d91d6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Today is a beautiful day! Tomorrow looks like bad weather.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad530e7-708d-45a4-977f-532786df23d5",
   "metadata": {},
   "source": [
    "## Translate to Spanish\n",
    "* Automatically figures out source language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3417c513-c621-4853-8cdd-eff60726a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_text = translate(text, 'Spanish')\n",
    "spanish_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23022b4b-cb38-4b55-a6eb-75b551df055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_text = translate(text, 'Chinese')\n",
    "chinese_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a866b1f-99e0-47c1-9770-a7d4e9894bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_speech(spanish_text, 'Spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e6226b-a824-409b-8e53-93ff44bdc895",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio('Spanish.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda0dfe-8192-4938-ac07-ccd1443f428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_speech(chinese_text, 'Chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db52c174-0f8c-42c4-be37-e2036798e12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio('Chinese.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c040fd2-8d56-476a-b010-04a43ed41b22",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ea9be9-099a-4fe5-b737-a26c9c64b3b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generating Python Code with the Chat Completions API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15df2cd-7104-4f3c-9ffd-43166d5fd844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o-2024-08-06',\n",
    "    messages=[\n",
    "        {'role': 'system', \n",
    "         'content': 'You are an expert Python programmer.'},\n",
    "        {'role': 'user', \n",
    "         'content': \"\"\"Write Python code that uses the word_cloud \n",
    "             Python library to generate a 1000 pixel by 1000 pixel \n",
    "             rainbow color word cloud from the top 200 words in the \n",
    "             file 'RomeoAndJuliet.txt' which is in the current folder. \n",
    "             Remove both modern English and old English stop words. \n",
    "             Use the mask image named mask_heart.png, which is also in \n",
    "             the current folder. Display the generated word cloud.\"\"\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ad4e7a-3aff-43a3-a8d0-c376d893e9fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da492e-7ad6-4f03-aaca-13e6495faf4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load the text from 'RomeoAndJuliet.txt'\n",
    "with open('RomeoAndJuliet.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Define modern and old English stopwords\n",
    "modern_stopwords = set(STOPWORDS)\n",
    "old_english_stopwords = {\n",
    "    'thou', 'thee', 'thy', 'thine', 'ye', 'hath', 'hast', 'dost', 'art', 'hence', 'whence', 'whither', 'wither', 'canst',\n",
    "    'shalt', 'ought', 'wert', 'wherefore', 'oft', 'bid', 'nay', 'yon', 'tis', 'twas', 'ere'\n",
    "}\n",
    "\n",
    "# Combine modern and old English stopwords\n",
    "all_stopwords = modern_stopwords.union(old_english_stopwords)\n",
    "\n",
    "# Load the mask image\n",
    "mask_image = np.array(Image.open('mask_heart.png'))\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(width=1000, height=1000,\n",
    "                      stopwords=all_stopwords,\n",
    "                      mask=mask_image,\n",
    "                      max_words=200,\n",
    "                      color_func=lambda *args, **kwargs: (255, 0, 0, 255),\n",
    "                      contour_color='white',\n",
    "                      contour_width=1,\n",
    "                      relative_scaling=0.5).generate(text)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(10, 10), facecolor='k')\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef037093-9ad7-43d3-a1be-bd8d96020f57",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe02020b-28a6-4081-851c-ea924d8e622b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generating an Image with the Image API using Dall-E 3\n",
    "* Generated Sunday using the Image API's `'dall-e-3'` model\n",
    "> <img src=\"HavaneseDog.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62056b0a-5011-4d1f-99cb-49142ccc94e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = client.images.generate(\n",
    "    model='dall-e-3',\n",
    "    prompt=\"\"\"Havanese dog as a japanese anime character  \n",
    "              in neon colors against a black background\"\"\",\n",
    "    quality='hd'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ff29e-bf3b-48b3-9883-486f7f22bc7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec2be28-263a-4857-bf58-3b5c07e66c62",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response.data[0].url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905b86e3-6282-4a53-b974-34b7d65f430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(url=response.data[0].url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdfa11b-5336-4014-9282-c2a94fbe852d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response2 = client.images.generate(\n",
    "    model='dall-e-3',\n",
    "    prompt=\"\"\"Havanese dog in the style of Vincent Van Gogh\"\"\",\n",
    "    quality='hd'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a412e117-7bea-46e6-b44e-acbbe5c26951",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299e6a95-aae3-40d9-acbe-3793ca74d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(url=response2.data[0].url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fab18e-9347-45a9-934d-7829b1890ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response3 = client.images.generate(\n",
    "    model='dall-e-3',\n",
    "    prompt=\"\"\"Havanese dog in the style of Leonardo DaVinci\"\"\",\n",
    "    quality='hd'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6c76cb-8a80-459d-9905-7778fe688aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489c43d-ed73-49dc-9578-2dc6295921e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(url=response3.data[0].url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab24a49-9356-4e3b-add1-a41a2197d574",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da9e585-f52f-4bff-a0e7-09f0dd651218",
   "metadata": {},
   "source": [
    "# Other Cool Stuff To Check Out\n",
    "* ChatGPT as a Data Analytics Tool ― https://mitsloanedtech.mit.edu/ai/tools/data-analysis/how-to-use-chatgpts-advanced-data-analysis-feature/\n",
    "* OpenAI Playground ― https://platform.openai.com/playground\n",
    "* 7 Best AI Art Generators ― https://www.techrepublic.com/article/best-ai-art-generators/\n",
    "* Top 20 ChatGPT Prompts For Software Developers ― https://www.geeksforgeeks.org/chatgpt-prompts-for-software-developers/\n",
    "* OpenAI Developer Forum ― https://community.openai.com/\n",
    "* Google Project Gemini ― https://blog.google/technology/ai/google-gemini-ai/\n",
    "* Vectorizer.ai — Converts generated images to vector graphics ― https://vectorizer.ai\n",
    "* \"A Very Gentle Introduction to Large Language Models without the Hype\" by Mark Riedl, Georgia Tech Professor ― https://mark-riedl.medium.com/a-very-gentle-introduction-to-large-language-models-without-the-hype-5f67941fa59e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af5df17-63c1-4bc9-827e-953b74feaeef",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "&copy; 2024 by Deitel & Associates, Inc. All Rights Reserved. https://deitel.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
